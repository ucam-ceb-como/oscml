{
"numerical_settings":{
	"seed": 1,
    "cudnn_deterministic": true,
    "cudnn_benchmark": false
},
"dataset":{
    "src": "./data/processed/CEPDB_25000.csv",
    "z-stand": "False",
    "x_column": ["SMILES_str"],
    "y_column": ["pce"],
	"split": "ml_phase"
    },
"model":{
    "name": "AttentiveFP",
	"model_specific":{
		"graph_feat_size": {"type":"int","low":8,"high":256},
		"num_layers":{"type":"int","low":1,"high":6},
		"num_timesteps":{"type":"int","low":1,"high":4},
		"dropout":{"type":"uniform","low":0.0,"high":0.3}
		},
	"type_dict": "CEP25000",
	"featurizer": "full"
	},
"training":{
	"optimiser":{
		"name":"Adam",
		"lr":{"type":"loguniform","low":1e-5,"high":1e-2},
		"weight_decay":{"type":"loguniform","low":1e-5,"high":0.01}
		},
	"batch_size": 250,
	"epochs": 10,
	"patience": -1,
	"metric": "val_loss",
	"direction": "minimize",
	"__remove_this_bit__study_name": "attentivefp_cep25000_stratified",
	"__remove_this_bit__storage": "sqlite:///attentivefp_cep25000_stratified.db",
	"__remove_this_bit__load_if_exists": true,
	"__remove_this_bit__n_trials": 1,
	"__remove_this_bit__n_jobs": 1
    }
}
